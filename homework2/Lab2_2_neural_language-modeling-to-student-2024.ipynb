{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "15QfB7RAuXAc"
   },
   "source": [
    "# Neural Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gucid6KNuXAe"
   },
   "source": [
    "In this Exercise, we will be using Pytorch Lightning to implement our neural LM. Your job will be just to write the forward method of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yL_M2zf4myYa"
   },
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MRRrn78ZjL54",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0802efdb-2c17-49c2-a677-bcacf29ad0c4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2025-01-17 06:37:19--  https://github.com/ekapolc/nlp_2019/raw/master/HW4/BEST2010.zip\n",
      "Resolving github.com (github.com)... 140.82.116.4\n",
      "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW4/BEST2010.zip [following]\n",
      "--2025-01-17 06:37:20--  https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW4/BEST2010.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7423530 (7.1M) [application/zip]\n",
      "Saving to: ‘BEST2010.zip’\n",
      "\n",
      "BEST2010.zip        100%[===================>]   7.08M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2025-01-17 06:37:20 (71.4 MB/s) - ‘BEST2010.zip’ saved [7423530/7423530]\n",
      "\n",
      "Archive:  BEST2010.zip\n",
      "   creating: BEST2010/\n",
      "  inflating: BEST2010/article.txt    \n",
      "  inflating: BEST2010/encyclopedia.txt  \n",
      "  inflating: BEST2010/news.txt       \n"
     ]
    }
   ],
   "source": [
    "# #download corpus\n",
    "!wget --no-check-certificate https://github.com/ekapolc/nlp_2019/raw/master/HW4/BEST2010.zip\n",
    "!unzip BEST2010.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SGmYebp38OUl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4df8e0e3-9d36-4d4b-b115-3bc23267211c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m185.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%pip install -q lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR4HK5jQm17K"
   },
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oPE1RqKOrWJ0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a6b9acca-3e77-4ada-846f-20df080eb460"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total sentences in BEST2010 news training dataset :\t21678\n",
      "Total word counts in BEST2010 news training dataset :\t1042797\n"
     ]
    }
   ],
   "source": [
    "total_word_count = 0\n",
    "best2010 = []\n",
    "with open(\"BEST2010/news.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        line = line.strip()[:-1]  # remove the trailing |\n",
    "        total_word_count += len(line.split(\"|\"))\n",
    "        best2010.append(line)\n",
    "\n",
    "train = best2010[: int(len(best2010) * 0.7)]\n",
    "test = best2010[int(len(best2010) * 0.7) :]\n",
    "# Training data\n",
    "train_word_count = 0\n",
    "for line in train:\n",
    "    for word in line.split(\"|\"):\n",
    "        train_word_count += 1\n",
    "print(\"Total sentences in BEST2010 news training dataset :\\t\" + str(len(train)))\n",
    "print(\"Total word counts in BEST2010 news training dataset :\\t\" + str(train_word_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQBjqe5arHGX"
   },
   "source": [
    "Here we are going to use a library from huggingface called `tokenizers`. This will help us create a vocabulary and handle the encoding and decoding, i.e., convert text to its corresponding ID (which will be learned by the tokenizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "elwE0gh2rE3C"
   },
   "outputs": [],
   "source": [
    "%pip install -q tokenizers\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import CharDelimiterSplit\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "\n",
    "# Basically, we just use the new tokenizer as our vocab building tool.\n",
    "# In practice, you will have to use a compatible tokenizer like newmm to tokenize the corpus first then do this step\n",
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = CharDelimiterSplit(delimiter=\"|\")  # now the tokenizer will split \"|\" for us\n",
    "trainer = WordLevelTrainer(\n",
    "    min_frequency=3,  # we can set a frequency threshold for taking a word into our vocab. for this example, words with freq < 3 will be excluded from the vocab.\n",
    "    special_tokens=[\"[UNK]\", \"<s>\", \"</s>\"],\n",
    ")  # these are our special tokens: for unknown, begin-of-sentence, and end-of-sentence, respectively.\n",
    "tokenizer.train_from_iterator(train, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TrKtjv4PJpg2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dffd0252-33d8-4f89-8cc0-679c9c28f2a6"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9062"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(tokenizer.get_vocab())  # same as nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WqM_jrZwrJpB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b8b6994d-cbb7-4f0e-f5d8-7faa879c94e5"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['กฎหมาย', 'กับ', 'การ', 'เบียดบัง', 'คน', 'จน', '[UNK]']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "tokenizer.encode(\n",
    "    \"กฎหมาย|กับ|การ|เบียดบัง|คน|จน|asdf\"\n",
    ").tokens  # tokens we get after tokenizing this sentence. unknown words will be tokenized as [UNK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1r1pJ1B_sp9j",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ce45d6c3-ef47-4fd8-f36c-2e8610b9fb13"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[242, 28, 5, 8883, 22, 190, 0]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "tokenizer.encode(\"กฎหมาย|กับ|การ|เบียดบัง|คน|จน|asdf\").ids  # this is what we will feed to the LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Fkx6CSoXWXmG"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import lightning as L\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3XHJsP8_898x",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0af875ca-f47b-4dd8-ae28-29f8a6a73ae5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO: Seed set to 42\n",
      "INFO:lightning.fabric.utilities.seed:Seed set to 42\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "L.seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-r_kyrrrDHZq"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, seq_len=128):\n",
    "        #  data is currently a list of sentences\n",
    "        #  [sent1,\n",
    "        #   sent2,\n",
    "        #   ...,\n",
    "        #  ]\n",
    "\n",
    "        data = [d + \"|</s>\" for d in data]  # append an </s> token to each sentence\n",
    "        encodings = tokenizer.encode_batch(data)  # encode (turn token into token_id) data\n",
    "        token_ids = [enc.ids for enc in encodings]  # get the token ids for each sentence\n",
    "        flatten_token_ids = list(itertools.chain(*token_ids))  # turn a list of token_ids into one long token_ids\n",
    "        ## now data looks like this [sent1_ids </s> sent2_ids </s> ...]\n",
    "        encoded = torch.LongTensor(flatten_token_ids)\n",
    "\n",
    "        # remove some left over tokens so that we can form batches of seq_len (128 in this case). Optionally, we can use padding tokens instead.\n",
    "        left_over = len(encoded) % seq_len\n",
    "        encoded = encoded[: len(encoded) - left_over]\n",
    "        self.encoded = encoded.view(\n",
    "            -1, seq_len\n",
    "        )  # reshape data so it becomes a 2-D matrix of shape (len(encoded)//128, 128), i.e. each row contains data of len==128\n",
    "        ## now data looks like this\n",
    "        ## [ [1,2,3, ... , 128] (this is just an example, not actual input_ids)\n",
    "        ##   [1,2,3, ... , 128]\n",
    "        ##   [1,2,3, ... , 128]\n",
    "        ## ]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YmW-K0XBZ4Dq"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 128\n",
    "train_dataset = TextDataset(train)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")  # DataLoader will take care of the random sampling and batching of data\n",
    "\n",
    "test_dataset = TextDataset(test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElhZcB94MUtC"
   },
   "source": [
    "## Model : Implement the forward function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nKNJAolug-1I"
   },
   "outputs": [],
   "source": [
    "class LSTM(L.LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, learning_rate, criterion):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)  # this will turn the token ids into vectors\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, dropout=dropout_rate, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)  # turn the vectors back into token ids\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        embedded = self.dropout(embedded)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        prediction = self.fc(lstm_out)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        src = batch[:, :-1]\n",
    "        target = batch[:, 1:]\n",
    "        prediction = self(src)  # run the sequence through the model (the forward method)\n",
    "        prediction = prediction.reshape(-1, self.vocab_size)\n",
    "        target = target.reshape(-1)\n",
    "        loss = self.criterion(prediction, target)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        src = batch[:, :-1]  # [batch_size (64) , seq_len-1 (127)] except last words\n",
    "        target = batch[:, 1:]  # [batch_size (64) , seq_len-1 (127)] except first words\n",
    "        with torch.no_grad():  # disable gradient calculation for faster inference\n",
    "            prediction = self(src)  # [batch_size (64), seq_len-1 (127) , vocab size (9000)]\n",
    "        prediction = prediction.reshape(-1, self.vocab_size)  # [batch_size*(seq_len-1) (64*127=8128) , vocab]\n",
    "        target = target.reshape(-1)  # [batch_size (64), seq_len-1 (127)] -> [batch_size*(seq_len-1) (8128)]\n",
    "        loss = self.criterion(prediction, target)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jBnYCh-miOEr"
   },
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embedding_dim = 200\n",
    "hidden_dim = 512\n",
    "num_layers = 3\n",
    "dropout_rate = 0.2\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HHWXaPsvigPq"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model = LSTM(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, lr, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_yNEZ4jwXumR"
   },
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZwqhWicMdH0"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kr0zdeMAjD1U",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "80f7b26d-8598-4040-b037-855e9cb03dc4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=20, logger=csv_logger, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "A9qcwNA0mN6J",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656,
     "referenced_widgets": [
      "c1fe879f59df44eb8b5382b182e9136b",
      "1f1d02524ee24c29861e217236aea67d",
      "6bd5663c74034868a6f9d21cab4ff8cc",
      "fcd00fd37f244c369a165ac548454fe8",
      "1a152df3850a482b9d36af3593c58683",
      "76ed6365d6cb4f6e87bcab7c1dd03daa",
      "72167ea51a4544e3b4dc69e1c5c2b06d",
      "e0d6acedf1c346fa914835b3f4bbc12f",
      "f4dea336ff404ead8fbee41200331e89",
      "32d9556cccef474694725fca4a496305",
      "39e0355179874e98974c9151f7a09da0"
     ]
    },
    "outputId": "52c62565-7760-42c1-df11-9a0fbdda6bd7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | embedding | Embedding        | 1.8 M  | train\n",
      "1 | lstm      | LSTM             | 5.7 M  | train\n",
      "2 | dropout   | Dropout          | 0      | train\n",
      "3 | fc        | Linear           | 4.6 M  | train\n",
      "4 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "12.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.1 M    Total params\n",
      "48.504    Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | embedding | Embedding        | 1.8 M  | train\n",
      "1 | lstm      | LSTM             | 5.7 M  | train\n",
      "2 | dropout   | Dropout          | 0      | train\n",
      "3 | fc        | Linear           | 4.6 M  | train\n",
      "4 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "12.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.1 M    Total params\n",
      "48.504    Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1fe879f59df44eb8b5382b182e9136b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader)  # takes about 8 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUfWF_V6Me9H"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "WXVj9ewNqweZ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167,
     "referenced_widgets": [
      "be3c2d1d16e2432db878035d1b41d632",
      "cff033e094c64375a7cd87d9de19c530",
      "70fbd3f1dbbb464fb7206851d7a710c8",
      "10519756eb0b42f6b5f2b31f235a3cb6",
      "63574ebd212f4097b42606a12a7a4f32",
      "458f8bd9eed64640959a8fe90b71e4e2",
      "dde092b0246b43a5a2ef63a62d24fa35",
      "7158a012d6d243a69126d70a9ea2aee1",
      "217f4f69ac8f415a9184fca36f7c3594",
      "bb486de12e0b4f4c9e7eaed569dfa90e",
      "ff99d197a30b46f7a3bd4e575e86a385"
     ]
    },
    "outputId": "015dfca5-335a-4dae-bd1d-ac50a550d900"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be3c2d1d16e2432db878035d1b41d632"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   4.1082844734191895    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    4.1082844734191895     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "test_result = trainer.test(model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4pVjEyYDtnc-"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uuIPToGQs-ZG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "19921b87-7b19-48f3-a747-f90f0c77c848"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Perplexity : 60.84225148840851\n"
     ]
    }
   ],
   "source": [
    "print(f\"Perplexity : {np.exp(test_result[0]['test_loss'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pAZwiRqsnOPe",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e9987a77-0d65-4522-9f7d-28f16a45050d"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(9062, 200)\n",
       "  (lstm): LSTM(200, 512, num_layers=3, batch_first=True, dropout=0.2)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=9062, bias=True)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "model.eval()  # disable dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "VFtebDAmVh_T"
   },
   "outputs": [],
   "source": [
    "unk_token_id = tokenizer.encode(\"[UNK]\").ids\n",
    "eos_token_id = tokenizer.encode(\"</s>\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "hj-V4OsDqpBO"
   },
   "outputs": [],
   "source": [
    "def generate_seq(context, max_new_token=10):\n",
    "    encoded = tokenizer.encode(context).ids\n",
    "    with torch.no_grad():\n",
    "        for i in range(max_new_token):\n",
    "            src = torch.LongTensor([encoded]).to(model.device)\n",
    "            prediction = model(src)\n",
    "            probs = torch.softmax(prediction[:, -1] / 1, dim=-1)\n",
    "            prediction = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "            while prediction == unk_token_id:\n",
    "                prediction = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "            if prediction == eos_token_id:\n",
    "                break\n",
    "\n",
    "            encoded.append(prediction)\n",
    "\n",
    "    return tokenizer.decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "u20r9w8zvJi4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "437ae93a-3568-42b1-dcd1-40695dbe7dfd"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'จน รู้ หุ้น ไม่ สามารถ ตรวจสอบ ตาม เวลา บาง ครั้ง'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "context = \"<s>\"\n",
    "generate_seq(context, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fr536NVvGX3"
   },
   "source": [
    "## Questions: Answer the following in MyCourseville\n",
    "\n",
    "1. What is the perplexity of the neural LM you trained?\n",
    "2. Paste your favorite sentence generated with the LM."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "c1fe879f59df44eb8b5382b182e9136b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f1d02524ee24c29861e217236aea67d",
       "IPY_MODEL_6bd5663c74034868a6f9d21cab4ff8cc",
       "IPY_MODEL_fcd00fd37f244c369a165ac548454fe8"
      ],
      "layout": "IPY_MODEL_1a152df3850a482b9d36af3593c58683"
     }
    },
    "1f1d02524ee24c29861e217236aea67d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76ed6365d6cb4f6e87bcab7c1dd03daa",
      "placeholder": "​",
      "style": "IPY_MODEL_72167ea51a4544e3b4dc69e1c5c2b06d",
      "value": "Epoch 19: 100%"
     }
    },
    "6bd5663c74034868a6f9d21cab4ff8cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0d6acedf1c346fa914835b3f4bbc12f",
      "max": 130,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f4dea336ff404ead8fbee41200331e89",
      "value": 130
     }
    },
    "fcd00fd37f244c369a165ac548454fe8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32d9556cccef474694725fca4a496305",
      "placeholder": "​",
      "style": "IPY_MODEL_39e0355179874e98974c9151f7a09da0",
      "value": " 130/130 [00:23&lt;00:00,  5.62it/s, v_num=0]"
     }
    },
    "1a152df3850a482b9d36af3593c58683": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "76ed6365d6cb4f6e87bcab7c1dd03daa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72167ea51a4544e3b4dc69e1c5c2b06d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0d6acedf1c346fa914835b3f4bbc12f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4dea336ff404ead8fbee41200331e89": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "32d9556cccef474694725fca4a496305": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39e0355179874e98974c9151f7a09da0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be3c2d1d16e2432db878035d1b41d632": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cff033e094c64375a7cd87d9de19c530",
       "IPY_MODEL_70fbd3f1dbbb464fb7206851d7a710c8",
       "IPY_MODEL_10519756eb0b42f6b5f2b31f235a3cb6"
      ],
      "layout": "IPY_MODEL_63574ebd212f4097b42606a12a7a4f32"
     }
    },
    "cff033e094c64375a7cd87d9de19c530": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_458f8bd9eed64640959a8fe90b71e4e2",
      "placeholder": "​",
      "style": "IPY_MODEL_dde092b0246b43a5a2ef63a62d24fa35",
      "value": "Testing DataLoader 0: 100%"
     }
    },
    "70fbd3f1dbbb464fb7206851d7a710c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7158a012d6d243a69126d70a9ea2aee1",
      "max": 39,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_217f4f69ac8f415a9184fca36f7c3594",
      "value": 39
     }
    },
    "10519756eb0b42f6b5f2b31f235a3cb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb486de12e0b4f4c9e7eaed569dfa90e",
      "placeholder": "​",
      "style": "IPY_MODEL_ff99d197a30b46f7a3bd4e575e86a385",
      "value": " 39/39 [00:04&lt;00:00,  8.77it/s]"
     }
    },
    "63574ebd212f4097b42606a12a7a4f32": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "458f8bd9eed64640959a8fe90b71e4e2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dde092b0246b43a5a2ef63a62d24fa35": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7158a012d6d243a69126d70a9ea2aee1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "217f4f69ac8f415a9184fca36f7c3594": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bb486de12e0b4f4c9e7eaed569dfa90e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff99d197a30b46f7a3bd4e575e86a385": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}