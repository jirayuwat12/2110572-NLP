{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "15QfB7RAuXAc"
   },
   "source": [
    "# Language Modeling using Ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gucid6KNuXAe"
   },
   "source": [
    "In this Exercise, we are going to create a bigram language model and its variation. We will build one model for each of the following type and calculate their perplexity:\n",
    "- Unigram Model\n",
    "- Bigram Model\n",
    "- Bigram Model with Laplace smoothing\n",
    "- Bigram Model with Interpolation\n",
    "- Bigram Model with Kneser-ney Interpolation\n",
    "\n",
    "We will also use NLTK which is a natural language processing library for python to make our lives easier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "MRRrn78ZjL54"
   },
   "outputs": [],
   "source": [
    "# #download corpus\n",
    "# !wget --no-check-certificate https://github.com/ekapolc/nlp_2019/raw/master/HW4/BEST2010.zip\n",
    "# !unzip BEST2010.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "qeyvLSptdKXj"
   },
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/jajdlqnp5h0ywvo/tokenized_wiki_sample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "GjJDeG03uXAf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# First we import necessary library such as math, nltk, bigram, and collections.\n",
    "%pip install -q nltk\n",
    "import math\n",
    "import nltk\n",
    "import io\n",
    "import random\n",
    "from random import shuffle\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "random.seed(999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HugXBHNEuXAh"
   },
   "source": [
    "BEST2010 is a free Thai NLP dataset by NECTEC usually used as a standard benchmark for various NLP tasks including language modeling. It is separated into 4 domains including article, encyclopedia, news, and novel. The data is already  tokenized using '|' as a separator.\n",
    "\n",
    "For example,\n",
    "\n",
    "ตาม|ที่|นางประนอม ทองจันทร์| |กับ| |ด.ช.กิตติพงษ์ แหลมผักแว่น| |และ| |ด.ญ.กาญจนา กรองแก้ว| |ป่วย|สงสัย|ติด|เชื้อ|ไข้|ขณะ|นี้|ยัง|ไม่|ดี|ขึ้น|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "iu-AJSZZuXAi"
   },
   "outputs": [],
   "source": [
    "total_word_count = 0\n",
    "best2010 = []\n",
    "with open(\"BEST2010/news.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        line = line.strip()[:-1]  # remove the trailing |\n",
    "        total_word_count += len(line.split(\"|\"))\n",
    "        best2010.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "3WfpGgbruXAj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in BEST2010 news dataset :\t30969\n",
      "Total word counts in BEST2010 news dataset :\t1660190\n"
     ]
    }
   ],
   "source": [
    "# For simplicity, we assumes that each line is a sentence.\n",
    "print(f\"Total sentences in BEST2010 news dataset :\\t{len(best2010)}\")\n",
    "print(f\"Total word counts in BEST2010 news dataset :\\t{total_word_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JD9iXF1uXAm"
   },
   "source": [
    "We separate the input into 2 sets, train and test data with 70:30 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "_WGcQq_juXAm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in BEST2010 news training dataset :\t21678\n",
      "Total word counts in BEST2010 news training dataset :\t1042797\n"
     ]
    }
   ],
   "source": [
    "sentences = best2010\n",
    "# The data is separated to train and test set with 70:30 ratio.\n",
    "train = sentences[: int(len(sentences) * 0.7)]\n",
    "test = sentences[int(len(sentences) * 0.7) :]\n",
    "\n",
    "# Training data\n",
    "train_word_count = 0\n",
    "for line in train:\n",
    "    for word in line.split(\"|\"):\n",
    "        train_word_count += 1\n",
    "print(\"Total sentences in BEST2010 news training dataset :\\t\" + str(len(train)))\n",
    "print(\"Total word counts in BEST2010 news training dataset :\\t\" + str(train_word_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17x6tW-3ae7Z"
   },
   "source": [
    "Here we load the data from Wikipedia which is also already tokenized. It will be used for answering questions in MyCourseville."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "0fAl6dTg_9HG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wiki_data = pd.read_csv(\"tokenized_wiki_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1W5bm-hbQXa"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Before training any language models, the first step we always do is process the data into the format suited for the LM.\n",
    "\n",
    "For this exercise, we will use NLTK to help process our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "4OIqxJB7P29D"
   },
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import pad_both_ends, flatten\n",
    "from nltk.lm.vocabulary import Vocabulary\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oy0ZN2_0bzRr"
   },
   "source": [
    "We begin by \"tokenizing\" our training set. Note that the data is already tokenized so we can just split it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "WQM0PXnXbzCN"
   },
   "outputs": [],
   "source": [
    "tokenized_train = [[\"<s>\"] + t.split(\"|\") + [\"</s>\"] for t in train]  # \"tokenize\" each sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TM2ylNRNcrg9"
   },
   "source": [
    "Next we create a vocabulary with the ```Vocabulary``` class from NLTK. It accepts a list of tokens so we flatten our sentences into one long sentence first.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Tbp-VmkHcq4d"
   },
   "outputs": [],
   "source": [
    "flat_tokens = list(flatten(tokenized_train))  # join all sentences into one long sentence\n",
    "vocab = Vocabulary(\n",
    "    flat_tokens, unk_cutoff=3\n",
    ")  # Words with frequency **below** 3 (not exactly 3) will not be considered in our vocab and will be converted to <UNK>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFnBHe6ScAaV"
   },
   "source": [
    "Then we replace low frequency words and pad each sentence with \\<s\\> in the front and \\</s\\> in the back of each sentence.\n",
    "\n",
    "Now *each* sentence is going to look something like this:\n",
    "\\[\"\\<s\\>\", \"hello\", \"my\", \"name\", \"is\", \"\\<UNK\\>\", \"\\</s\\>\" \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "9q6QakuibxqN"
   },
   "outputs": [],
   "source": [
    "tokenized_train = [[token if token in vocab else \"<UNK>\" for token in sentence] for sentence in tokenized_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dn6GxaSFeSpD"
   },
   "source": [
    "Finally, we do the same for the test set and the wiki dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "D4N6qKrPadIj"
   },
   "outputs": [],
   "source": [
    "tokenized_test = [t.split(\"|\") for t in test]\n",
    "tokenized_test = [[token if token in vocab else \"<UNK>\" for token in sentence] for sentence in tokenized_test]\n",
    "\n",
    "tokenized_wiki_test = [t.split(\"|\") for t in wiki_data[\"tokenized\"].tolist()]\n",
    "tokenized_wiki_test = [[token if token in vocab else \"<UNK>\" for token in sentence] for sentence in tokenized_wiki_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHtCMFMluXAo"
   },
   "source": [
    "# Unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2V1WQTGzuXAp"
   },
   "source": [
    "In this section, we will demonstrate how to build a unigram language model <br>\n",
    "**Important note:** <br>\n",
    "**\\<s\\>** = sentence start symbol <br>\n",
    "**\\</s\\>** = sentence end symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xd7qOd7KAYWM"
   },
   "source": [
    "# VERY IMPORTANT:\n",
    "- In this notebook, we will *not* default the unknown token probability to ```1/len(vocab)``` but instead will treat it as a normal word and let the model learn its probability so that we can compare our results to NLTK.\n",
    "- **Also make sure that the code in this notebook can be executed without any problem. If we find that you used NLTK to answer questions in MyCourseVille and did not finish the assignment, you will receive a grade of 0 for this assignment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "CTV-i9kdse58"
   },
   "outputs": [],
   "source": [
    "class UnigramModel:\n",
    "    def __init__(self, data, vocab):\n",
    "        self.unigram_count = defaultdict(lambda: 0.0)\n",
    "        self.word_count = 0\n",
    "        self.vocab = vocab\n",
    "        for sentence in data:\n",
    "            for w in sentence:  # [(word1, ), (word2, ), (word3, )...]\n",
    "                w = w[0]\n",
    "                self.unigram_count[w] += 1.0\n",
    "                self.word_count += 1\n",
    "\n",
    "    def __getitem__(self, w):\n",
    "        w = w[0]  # [(word1, ), (word2, ), (word3, )...]\n",
    "        if w in self.vocab:\n",
    "            return self.unigram_count[w] / (self.word_count)\n",
    "        else:\n",
    "            return self.unigram_count[\"<UNK>\"] / (self.word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "FnWJJ8Hqs8Qs"
   },
   "outputs": [],
   "source": [
    "train_unigrams = [list(ngrams(sent, n=1)) for sent in tokenized_train]  # creating the unigrams by setting n=1\n",
    "model = UnigramModel(train_unigrams, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "6coGxSY7uXAt"
   },
   "outputs": [],
   "source": [
    "def getLnValue(x):\n",
    "    if x == 0:\n",
    "        return -math.inf\n",
    "    return math.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "cFy8yhZjuXAv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.571687039690381\n",
      "-3.952132570275872\n",
      "Problability of a sentence 4.877889285183675e-18\n"
     ]
    }
   ],
   "source": [
    "# problability of 'นายก'\n",
    "print(getLnValue(model[(\"นายก\",)]))\n",
    "\n",
    "# for example, problability of 'นายกรัฐมนตรี' which is an unknown word is equal to\n",
    "print(getLnValue(model[(\"นายกรัฐมนตรี\",)]))\n",
    "\n",
    "# problability of 'นายก' 'ได้' 'ให้' 'สัมภาษณ์' 'กับ' 'สื่อ'\n",
    "prob = (\n",
    "    getLnValue(model[(\"นายก\",)])\n",
    "    + getLnValue(model[(\"ได้\",)])\n",
    "    + getLnValue(model[(\"ให้\",)])\n",
    "    + getLnValue(model[(\"สัมภาษณ์\",)])\n",
    "    + getLnValue(model[(\"กับ\",)])\n",
    "    + getLnValue(model[(\"สื่อ\",)])\n",
    "    + getLnValue(model[(\"</s>\",)])\n",
    ")\n",
    "print(\"Problability of a sentence\", math.exp(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8EfqnDsuXAw"
   },
   "source": [
    "# Perplexity\n",
    "\n",
    "In order to compare language model we need to calculate perplexity. In this task you should write a perplexity calculation code for the unigram model. The result perplexity should be around 420.67 and\n",
    "345.12 on train and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZHQ-6tVuXAx"
   },
   "source": [
    "## TODO #1 Calculate perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "kh0DwzoouXAx"
   },
   "outputs": [],
   "source": [
    "def getLnValue(x):\n",
    "    if x == 0:\n",
    "        return -math.inf\n",
    "    return math.log(x)\n",
    "\n",
    "\n",
    "def calculate_sentence_ln_prob(sentence, model):\n",
    "    \"\"\"Calculate the log probability of a sentence given a language model.\"\"\"\n",
    "    ln_prob = 0\n",
    "    for i in range(len(sentence)):\n",
    "        ln_prob += getLnValue(model[sentence[i]])\n",
    "    return ln_prob\n",
    "\n",
    "\n",
    "def perplexity(test, model):\n",
    "    \"\"\"Compute perplexity of the test set with a language model using sentence ln prob.\"\"\"\n",
    "    word_count = 0\n",
    "    ln_total = 0\n",
    "    for sentence in test:\n",
    "        ln_total += calculate_sentence_ln_prob(sentence, model)\n",
    "        word_count += len(sentence)\n",
    "    return math.exp(-ln_total / word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "X-t_8mEzRxT-"
   },
   "outputs": [],
   "source": [
    "test_unigrams = [list(ngrams(sent, n=1)) for sent in tokenized_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "PztVYprdtBja"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448.89690751824827\n",
      "392.74028966757214\n"
     ]
    }
   ],
   "source": [
    "print(perplexity(train_unigrams, model))\n",
    "print(perplexity(test_unigrams, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHnBXtt3b-OY"
   },
   "source": [
    "## Q1 MCV\n",
    "Calculate the perplexity of the model on the wiki test set and answer in MyCourseVille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "JRd6hF_WSBl_"
   },
   "outputs": [],
   "source": [
    "wiki_test_unigrams = [list(ngrams(sent, n=1)) for sent in tokenized_wiki_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "I_LiSohADNLC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485.7336366066887\n"
     ]
    }
   ],
   "source": [
    "print(perplexity([list(flatten(wiki_test_unigrams))], model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK0gaMf0uXA2"
   },
   "source": [
    "# Bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmTkAY_QuXA3"
   },
   "source": [
    "Next, you will create a better language model than a unigram (which is not much to compare with). But first, it is very tedious to count every pair of words that occur in our corpus by ourselves. Lucky for us, nltk provides us a simple library which will simplify the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "Lv6r2LJ1uXA4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is how nltk generate bigram.\n",
      "<s> I\n",
      "I always\n",
      "always search\n",
      "search google\n",
      "google for\n",
      "for an\n",
      "an answer\n",
      "answer .\n",
      ". </s>\n",
      "\n",
      "<s> and </s> are used as a start and end of sentence symbol. respectively.\n"
     ]
    }
   ],
   "source": [
    "# example of nltk usage for bigram\n",
    "sentence = \"I always search google for an answer .\"\n",
    "padded_sentence = list(pad_both_ends(sentence.split(), n=2))\n",
    "\n",
    "print(\"This is how nltk generate bigram.\")\n",
    "for w1, w2 in bigrams(padded_sentence):\n",
    "    print(w1, w2)\n",
    "print(\"\\n<s> and </s> are used as a start and end of sentence symbol. respectively.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5R2T-6i9uXA6"
   },
   "source": [
    "Now, you should be able to implement a bigram model by yourself. Also, you must create a new perplexity calculation for bigram. The result perplexity should be around 56.46 and 85.38 on train and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aYkjzTzuXA7"
   },
   "source": [
    "## TODO #3 Write Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "l4s7oSmjkNuU"
   },
   "outputs": [],
   "source": [
    "class BigramModel:\n",
    "    def __init__(self, data, vocab):\n",
    "        self.bigram_count = defaultdict(lambda: 0.0)\n",
    "        self.unigram_count = defaultdict(lambda: 0.0)\n",
    "        self.total_word_count = 0\n",
    "        self.vocab = vocab\n",
    "        for sentence in data:\n",
    "            for w1, w2 in sentence:  # [(word1, word2), (word2, word3), (word3, word4)...]\n",
    "                self.bigram_count[(w1, w2)] += 1.0\n",
    "                self.unigram_count[w1] += 1.0\n",
    "                self.total_word_count += 1\n",
    "\n",
    "    def __getitem__(self, bigram):\n",
    "        \"\"\"\n",
    "        Return the probability of a given bigram.\n",
    "        Note: Return least prob value if the bigram is not in the model.\n",
    "        \"\"\"\n",
    "        w1, w2 = bigram\n",
    "        if bigram in self.bigram_count:\n",
    "            return self.bigram_count[bigram] / self.unigram_count[w1]\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3_Cgu6guXA-"
   },
   "source": [
    "## TODO #4 Write Perplexity for Bigram Model\n",
    "\n",
    "Sum perplexity score at a sentence level, instead of word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "hICoAhZjAxo1"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def perplexity(bigram_data, model):\n",
    "    \"\"\"Compute perplexity of the test set with a language model using bigram ln prob.\"\"\"\n",
    "    sum_ln_prob = 0\n",
    "    looper = tqdm(bigram_data[0], position=0, leave=True, desc=\"Calculating perplexity\")\n",
    "    for index, (w1, w2) in enumerate(looper):\n",
    "        sum_ln_prob += getLnValue(model[(w1, w2)])\n",
    "        if index % 10000 == 0:\n",
    "            looper.set_postfix({\"current perplexity\": math.exp(-sum_ln_prob / (index + 1))})\n",
    "\n",
    "    return math.exp(-sum_ln_prob / len(bigram_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "NxJYI3_TS2gf"
   },
   "outputs": [],
   "source": [
    "train_bigrams = [list(ngrams(sent, n=2)) for sent in tokenized_train]\n",
    "test_bigrams = [list(ngrams(sent, n=2)) for sent in tokenized_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "A4DD_RPFtxUo"
   },
   "outputs": [],
   "source": [
    "bigram_model_scratch = BigramModel(train_bigrams, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "yw4BubpbtuV7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 1064475/1064475 [00:00<00:00, 2186708.50it/s, current perplexity=56.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.45504870219316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 17/17 [00:00<00:00, 52622.26it/s, current perplexity=1.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 608102/608102 [00:00<00:00, 2155564.01it/s, current perplexity=inf]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(perplexity([list(flatten(train_bigrams))], bigram_model_scratch))\n",
    "print(perplexity([list(flatten(test_bigrams))[:17]], bigram_model_scratch))\n",
    "print(perplexity([list(flatten(test_bigrams))], bigram_model_scratch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRv294uQcZFC"
   },
   "source": [
    "## Q2 MCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "kCeRCyOIUWTS"
   },
   "outputs": [],
   "source": [
    "wiki_test_bigrams = [list(ngrams(sent, n=2)) for sent in tokenized_wiki_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "q47hutRqIg1z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 214930/214930 [00:00<00:00, 2152941.36it/s, current perplexity=inf]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(perplexity([list(flatten(wiki_test_bigrams))], bigram_model_scratch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BAF9DQbuXBC"
   },
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlm75BWLuXBC"
   },
   "source": [
    "Usually any ngram models have a sparsity problem, which means it does not have every possible ngram of words in the dataset. Smoothing techniques can alleviate this problem. In this section, you will implement three basic smoothing methods laplace smoothing, interpolation for bigram, and Knesey-Ney smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwa7YQiouXBD"
   },
   "source": [
    "## TODO #5 write Bigram with Laplace smoothing (Add-One Smoothing)\n",
    "\n",
    "The result perplexity on training and testing should be:\n",
    "\n",
    "    370.23, 361.25 for Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "j2Bw4C9T_UEs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 1064475/1064475 [00:00<00:00, 1977111.84it/s, current perplexity=371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370.28232024056035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 608102/608102 [00:00<00:00, 1625136.93it/s, current perplexity=369]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369.1605485652555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class BigramWithLaplaceSmoothing(BigramModel):\n",
    "    def __getitem__(self, bigram):\n",
    "        w1, w2 = bigram\n",
    "        return (self.bigram_count[(w1, w2)] + 1) / (self.unigram_count[w1] + len(self.vocab))\n",
    "\n",
    "\n",
    "model = BigramWithLaplaceSmoothing(train_bigrams, vocab)\n",
    "print(perplexity([list(flatten(train_bigrams))], model))\n",
    "print(perplexity([list(flatten(test_bigrams))], model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFT4uhIGhP0c"
   },
   "source": [
    "## Q3 MCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "jSH60cshIpDy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 214930/214930 [00:00<00:00, 1739308.31it/s, current perplexity=730]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735.0253999215859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(perplexity([list(flatten(wiki_test_bigrams))], model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JDswBSIuXBG"
   },
   "source": [
    "## TODO #6 Write Bigram with Interpolation\n",
    "Set the lambda value as 0.7 for bigram, 0.25 for unigram, and 0.05 for unknown word.\n",
    "\n",
    "The result perplexity on training and testing should be:\n",
    "\n",
    "    70.07, 102.67 for Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "PIeDBLarvZUT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 1064475/1064475 [00:00<00:00, 1364681.55it/s, current perplexity=70.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.06754793707988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 608102/608102 [00:00<00:00, 1257695.96it/s, current perplexity=103]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102.99295310997627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class BigramWithInterpolation:\n",
    "    def __init__(self, data, vocab, l=0.7):\n",
    "        self.unigram_count = defaultdict(lambda: 0.0)\n",
    "        self.bigram_count = defaultdict(lambda: 0.0)\n",
    "        self.total_word_count = 0\n",
    "        self.vocab = vocab\n",
    "        self.l = l  # l for lambda\n",
    "        for sentence in data:\n",
    "            for w1, w2 in sentence:\n",
    "                self.bigram_count[(w1, w2)] += 1.0\n",
    "                self.unigram_count[w1] += 1.0\n",
    "                self.total_word_count += 1\n",
    "\n",
    "            # account of the last word of each sentence\n",
    "            self.unigram_count[w2] += 1.0\n",
    "            self.total_word_count += 1\n",
    "\n",
    "    def __getitem__(self, bigram):\n",
    "        w1, w2 = bigram\n",
    "        unigram_prob = self.unigram_count[w2] / self.total_word_count\n",
    "        if w1 not in self.vocab:\n",
    "            w1 = \"<UNK>\"\n",
    "        if self.unigram_count[w1] == 0:\n",
    "            bigram_prob = 0\n",
    "        else:\n",
    "            bigram_prob = self.bigram_count[(w1, w2)] / self.unigram_count[w1]\n",
    "\n",
    "        return 0.7 * bigram_prob + 0.25 * unigram_prob + 0.05 * (1 / len(self.vocab))\n",
    "\n",
    "\n",
    "model = BigramWithInterpolation(train_bigrams, vocab)\n",
    "print(perplexity([list(flatten(train_bigrams))], model))\n",
    "print(perplexity([list(flatten(test_bigrams))], model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-GlmJUIhN7s"
   },
   "source": [
    "## Q4 MCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "EilXywU-IuNU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 214930/214930 [00:00<00:00, 1101110.98it/s, current perplexity=251]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251.60709095654997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(perplexity([list(flatten(wiki_test_bigrams))], model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUorP-EWuXBM"
   },
   "source": [
    "## Language modeling on multiple domains\n",
    "\n",
    "Sometimes, we do not have enough data to create a language model for a new domain. In that case, we can improvised by combining several models to improve result on the new domain.\n",
    "\n",
    "In this exercise you will try to merge two language models from news and article domains to create a language model for the encyclopedia domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "Jel9Hx69uXBN"
   },
   "outputs": [],
   "source": [
    "# create encyclopeida data (test data)\n",
    "encyclo_data = []\n",
    "with open(\"BEST2010/encyclopedia.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        encyclo_data.append(line.strip()[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jlla-S8YYRur"
   },
   "source": [
    "(news) First, you should try to calculate perplexity of your bigram with interpolation on encyclopedia data. The  perplexity should be around 236.329"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "gkRm8W4UWyfc"
   },
   "outputs": [],
   "source": [
    "encyclopedia_bigrams = [list(ngrams(pad_both_ends(sent.split(\"|\"), 2), n=2)) for sent in encyclo_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "x0l91qLEuXBP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 1214496/1214496 [00:01<00:00, 1167541.89it/s, current perplexity=468]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467.7718689489432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) news only on \"encyclopedia\"\n",
    "print(perplexity([list(flatten(encyclopedia_bigrams))], model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwV9j9U-uXBR"
   },
   "source": [
    "## TODO #7 - Langauge Modelling on Multiple Domains\n",
    "Combine news and article datasets to create another bigram model and evaluate it on the encyclopedia data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9skdgo8muXBO"
   },
   "source": [
    "\n",
    "\n",
    "(article) For your information, a bigram model with interpolation using article data to test on encyclopedia data has a perplexity of 218.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "LOA8fd53uXBU"
   },
   "outputs": [],
   "source": [
    "# 2) article only on \"encyclopedia\"\n",
    "best2010_article = []\n",
    "with open(\"BEST2010/article.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        best2010_article.append(line.strip()[:-1])\n",
    "\n",
    "combined_total_word_count = 0\n",
    "for line in best2010_article:\n",
    "    combined_total_word_count += len(line.split(\"|\"))\n",
    "\n",
    "article_bigrams = [list(ngrams(pad_both_ends(sent.split(\"|\"), 2), n=2)) for sent in best2010_article]\n",
    "article_vocab = Vocabulary(list(flatten([sent.split(\"|\") for sent in best2010_article])), unk_cutoff=3)\n",
    "\n",
    "model = BigramWithInterpolation(article_bigrams, article_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "7bLYcPvXYHkB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 1214496/1214496 [00:00<00:00, 1233036.06it/s, current perplexity=426]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of the bigram model using article data with interpolation smoothing on encyclopedia test data 426.31585617805587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Perplexity of the bigram model using article data with interpolation smoothing on encyclopedia test data\",\n",
    "    perplexity([list(flatten(encyclopedia_bigrams))], model),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "wBjmLhUcuXBS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 1214496/1214496 [00:01<00:00, 1115484.63it/s, current perplexity=398]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of the combined Bigram model with interpolation smoothing on encyclopedia test data 398.50315555053845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) train on news + article, test on \"encyclopedia\"\n",
    "best2010_article_and_news = best2010_article.copy()\n",
    "with open(\"BEST2010/news.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        best2010_article_and_news.append(line.strip()[:-1])\n",
    "\n",
    "combined_bigrams = [list(ngrams(pad_both_ends(sent.split(\"|\"), 2), n=2)) for sent in best2010_article_and_news]\n",
    "combined_vocab = Vocabulary(list(flatten([sent.split(\"|\") for sent in best2010_article_and_news])), unk_cutoff=3)\n",
    "\n",
    "combined_model = BigramWithInterpolation(combined_bigrams, combined_vocab)\n",
    "print(\n",
    "    \"Perplexity of the combined Bigram model with interpolation smoothing on encyclopedia test data\",\n",
    "    perplexity([list(flatten(encyclopedia_bigrams))], combined_model),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlFkJh-a_de8"
   },
   "source": [
    "## Q5 MCV\n",
    "\n",
    "Did you get a better or worse result when using combined data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNPEhD7WuXBV"
   },
   "source": [
    "## TODO #8 - Kneser-ney on \"News\"\n",
    "\n",
    "<!-- Reimplement equation 4.33 in SLP textbook (https://lagunita.stanford.edu/c4x/Engineering/CS-224N/asset/slp4.pdf) -->\n",
    "\n",
    "Implement Bigram Knerser-ney LM. The result perplexity should be around 65.81, 92.88 on train and test data. Be careful not to mix up vocab from the above section!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "Y_8xFf7tBqpc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting bigrams: 100%|██████████| 21678/21678 [00:00<00:00, 56863.12it/s]\n",
      "Calculating perplexity: 100%|██████████| 1000/1000 [00:05<00:00, 190.92it/s, current perplexity=5.76e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.40541747450013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 1000/1000 [00:05<00:00, 192.74it/s, current perplexity=1.93]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.82129031989595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class BigramKneserNey:\n",
    "    def __init__(self, data, vocab, discount=0.75):\n",
    "        self.bigram_count = defaultdict(lambda: 0.0)\n",
    "        self.unigram_count = defaultdict(lambda: 0.0)\n",
    "        self.total_word_count = 0\n",
    "        self.vocab = vocab\n",
    "        self.discount = discount\n",
    "        self.bigram_types = defaultdict(set)  # To store word types that follow a given word\n",
    "\n",
    "        # Count unigrams and bigrams\n",
    "        for sentence in tqdm(data, position=0, leave=True, desc=\"Counting bigrams\"):\n",
    "            for w1, w2 in sentence:  # sentence = [(word1, word2), (word2, word3), ...]\n",
    "                self.bigram_count[(w1, w2)] += 1.0\n",
    "                self.unigram_count[w1] += 1.0\n",
    "                self.bigram_types[w2].add(w1)  # w2 follows w1\n",
    "                self.total_word_count += 1\n",
    "\n",
    "    def continuation_probability(self, word):\n",
    "        \"\"\"\n",
    "        Compute continuation probability for a word based on how many unique bigrams end with it.\n",
    "        \"\"\"\n",
    "        return len(self.bigram_types[word]) / len(self.bigram_count)\n",
    "\n",
    "    def kneser_ney_probability(self, bigram):\n",
    "        \"\"\"\n",
    "        Return the smoothed probability for a given bigram using Kneser-Ney smoothing.\n",
    "        \"\"\"\n",
    "        w1, w2 = bigram\n",
    "        bigram_count = self.bigram_count[bigram]\n",
    "        unigram_count = self.unigram_count[w1]\n",
    "\n",
    "        # Discounted bigram probability\n",
    "        if unigram_count > 0:\n",
    "            p_bigram = max(bigram_count - self.discount, 0) / unigram_count\n",
    "        else:\n",
    "            p_bigram = 0\n",
    "\n",
    "        # Continuation probability\n",
    "        p_continuation = self.continuation_probability(w2)\n",
    "\n",
    "        # Weight of backoff\n",
    "        lambda_w1 = (\n",
    "            (self.discount / unigram_count) * len([w for w in self.bigram_count if w[0] == w1])\n",
    "            if unigram_count > 0\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        return p_bigram + lambda_w1 * p_continuation\n",
    "\n",
    "    def __getitem__(self, bigram):\n",
    "        \"\"\"\n",
    "        Return the Kneser-Ney smoothed probability of a given bigram.\n",
    "        \"\"\"\n",
    "        return self.kneser_ney_probability(bigram)\n",
    "\n",
    "\n",
    "model = BigramKneserNey(train_bigrams, vocab)\n",
    "# print(perplexity([list(flatten(train_bigrams))],model))\n",
    "print(perplexity([list(flatten(train_bigrams))[:1000]], model))\n",
    "print(perplexity([list(flatten(test_bigrams))[:1000]], model))\n",
    "# print(perplexity([list(flatten(test_bigrams))], model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULDScRw-g8Yn"
   },
   "source": [
    "## Q6 MCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "eSZ1Pb9WvfWC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 214930/214930 [19:55<00:00, 179.75it/s, current perplexity=246]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247.7732037817852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(perplexity([list(flatten(wiki_test_bigrams))], model))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
